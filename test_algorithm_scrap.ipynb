{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from make_df import create_df, make_inputs\n",
    "from naive import naive_fit, get_true_labels\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we test our custom 'Hard EM' algorithm against the following simpler alternatives for populating the missing cure labels:\n",
    "\n",
    "(I) Guessing that a censored individual is cured with a probability of 50%.\n",
    "\n",
    "(II) Creating one cluster from the noncensord individuals and two clusters from the cesnored individuals, then assigning cure\n",
    "labels to the censored individuals by comparing which of the two censored clusters is closer to the noncensored one, giving it the label '1' (not cured), and the furhter one the label '0'.\n",
    "\n",
    "This is achieved by creating test data sets in which we know exactly who is cured and who is censored, then removing the cure labels for the censored individuals, and feeding the censored and noncensored inputs into our algorithm. The latter is achieved\n",
    "using the 'naive_fit' function with the 'use_HardEM' option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To avoid a dataset with only one label we append the following extra columns.\n",
    "\n",
    "extra0 = pd.DataFrame([[0.1,0.1,0.1,0,1,0]],columns = ['x1', 'x2', 'x3', 'cure_label', 'int', 'censoring_indicator'])\n",
    "\n",
    "extra1 = pd.DataFrame([[0.1,0.1,0.1,1,1,1]],columns = ['x1', 'x2', 'x3', 'cure_label', 'int', 'censoring_indicator'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>cure_label</th>\n",
       "      <th>int</th>\n",
       "      <th>censoring_indicator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x1   x2   x3  cure_label  int  censoring_indicator\n",
       "0  0.1  0.1  0.1           0    1                    0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>cure_label</th>\n",
       "      <th>int</th>\n",
       "      <th>censoring_indicator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x1   x2   x3  cure_label  int  censoring_indicator\n",
       "0  0.1  0.1  0.1           1    1                    1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra = pd.concat([extra0, extra1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "r_weights = np.random.uniform(-0.5,0.5,(10,4)) #This will be used for the model parameter weights which we use to compute\n",
    "                                                #the cure lables for our test sets via sigmoid function.\n",
    "scores = []\n",
    "covariates = ['x1', 'x2', 'x3'] #We choose three covariates for our datasets for illustration.\n",
    "dist = [[0, 1], [0, 1], [0, 1]] #We are drawing covariates from a normal distribution with mean 0 and std 1.\n",
    "cols = ['censoring_indicator', 'cure_label']\n",
    "\n",
    "for test_model_weights in r_weights:\n",
    "    \n",
    "    foo = create_df(covariates, dist, 150, test_model_weights, 0.5) #We have 150 rows in our table and 0.5 is the probability\n",
    "                                                                    #of being censored given one is not cured we use to \n",
    "                                                                    #assign who is censored and who isn't.\n",
    "    foo = pd.concat([foo, extra])\n",
    "    \n",
    "    censored_inputs = make_inputs(foo, 0, cols)\n",
    "\n",
    "    noncensored_inputs = make_inputs(foo, 1, cols)\n",
    "    \n",
    "    fit = naive_fit(censored_inputs, noncensored_inputs, 'use_HardEM')    \n",
    "    \n",
    "    y_pred = fit['pred']\n",
    "    \n",
    "    y_true = get_true_labels(foo, ['censoring_indicator', 'cure_label'])\n",
    "    \n",
    "    y_scores = fit['prob']\n",
    "    \n",
    "    hard_acc = accuracy_score(y_true, y_pred) #'hard' is the score our algorithm produces. In this case, accuracy.\n",
    "    \n",
    "    hard_auc = roc_auc_score(y_true, y_scores)\n",
    "    \n",
    "    fit_naive = naive_fit(censored_inputs, noncensored_inputs, 'use_clustering') #See the opening description.\n",
    "    \n",
    "    y_pred_naive = fit_naive['pred']\n",
    "    \n",
    "    y_true_naive = get_true_labels(foo, ['censoring_indicator', 'cure_label'])\n",
    "    \n",
    "    y_scores_naive = fit_naive['prob']\n",
    "    \n",
    "    naive_acc = accuracy_score(y_true_naive, y_pred_naive) #The accuracy of the result produced by naive way of populating\n",
    "                                                           #the missing lables.\n",
    "    naive_auc = roc_auc_score(y_true_naive, y_scores_naive)\n",
    "    \n",
    "\n",
    "    scores.append([hard_auc, naive_auc, hard_acc, naive_acc ])\n",
    "    \n",
    "new_df = pd.DataFrame(columns=['HardEM_auc', 'NaiveEM_auc', 'HardEM_acc', 'NaiveEM_acc'], data=scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HardEM_auc</th>\n",
       "      <th>NaiveEM_auc</th>\n",
       "      <th>HardEM_acc</th>\n",
       "      <th>NaiveEM_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.996623</td>\n",
       "      <td>0.828312</td>\n",
       "      <td>0.782895</td>\n",
       "      <td>0.736842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.986255</td>\n",
       "      <td>0.792749</td>\n",
       "      <td>0.723684</td>\n",
       "      <td>0.776316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.926020</td>\n",
       "      <td>0.991969</td>\n",
       "      <td>0.796053</td>\n",
       "      <td>0.960526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.978946</td>\n",
       "      <td>0.737579</td>\n",
       "      <td>0.888158</td>\n",
       "      <td>0.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.853729</td>\n",
       "      <td>0.839373</td>\n",
       "      <td>0.480263</td>\n",
       "      <td>0.730263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.984857</td>\n",
       "      <td>0.751703</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.651316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.963070</td>\n",
       "      <td>0.815348</td>\n",
       "      <td>0.756579</td>\n",
       "      <td>0.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.997486</td>\n",
       "      <td>0.646697</td>\n",
       "      <td>0.756579</td>\n",
       "      <td>0.592105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.974740</td>\n",
       "      <td>0.752344</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.980064</td>\n",
       "      <td>0.997827</td>\n",
       "      <td>0.703947</td>\n",
       "      <td>0.960526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HardEM_auc  NaiveEM_auc  HardEM_acc  NaiveEM_acc\n",
       "0    0.996623     0.828312    0.782895     0.736842\n",
       "1    0.986255     0.792749    0.723684     0.776316\n",
       "2    0.926020     0.991969    0.796053     0.960526\n",
       "3    0.978946     0.737579    0.888158     0.684211\n",
       "4    0.853729     0.839373    0.480263     0.730263\n",
       "5    0.984857     0.751703    0.894737     0.651316\n",
       "6    0.963070     0.815348    0.756579     0.684211\n",
       "7    0.997486     0.646697    0.756579     0.592105\n",
       "8    0.974740     0.752344    0.828947     0.684211\n",
       "9    0.980064     0.997827    0.703947     0.960526"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A dataframe showing the results of the experiment\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How many times our accuracy was higher.\n",
    "\n",
    "len(new_df[new_df['HardEM_acc']-new_df['NaiveEM_acc']>0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How many times our AUC score was higher.\n",
    "\n",
    "len(new_df[new_df['HardEM_auc']-new_df['NaiveEM_auc']>0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_weights = np.random.uniform(-0.5,0.5,(10,4))\n",
    "scores = []\n",
    "covariates = ['x1', 'x2', 'x3']\n",
    "dist = [[0, 1], [0, 1], [0, 1]]\n",
    "cols = ['censoring_indicator', 'cure_label']\n",
    "\n",
    "for test_model_weights in r_weights: \n",
    "    \n",
    "    for p in probs:\n",
    "    \n",
    "        foo = create_df(covariates, dist, 150, test_model_weights, p)\n",
    "    \n",
    "        foo = pd.concat([foo, extra])\n",
    "    \n",
    "        censored_inputs = make_inputs(foo, 0, cols)\n",
    "\n",
    "        noncensored_inputs = make_inputs(foo, 1, cols)]\n",
    "    \n",
    "        fit = naive_fit(censored_inputs, noncensored_inputs, 'use_HardEM')    \n",
    "    \n",
    "        y_pred = fit['pred']\n",
    "    \n",
    "        y_true = get_true_labels(foo, ['censoring_indicator', 'cure_label'])\n",
    "    \n",
    "        y_scores = fit['prob']\n",
    "    \n",
    "        hard_acc = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "        hard_auc = roc_auc_score(y_true, y_scores)\n",
    "    \n",
    "        fit_naive = naive_fit(censored_inputs, noncensored_inputs, 'fifty_fifty')\n",
    "    \n",
    "        y_pred_naive = fit_naive['pred']\n",
    "    \n",
    "        y_true_naive = get_true_labels(foo, ['censoring_indicator', 'cure_label'])\n",
    "    \n",
    "        y_scores_naive = fit_naive['prob']\n",
    "    \n",
    "        naive_acc = accuracy_score(y_true_naive, y_pred_naive)\n",
    "    \n",
    "        naive_auc = roc_auc_score(y_true_naive, y_scores_naive)\n",
    "    \n",
    "\n",
    "        scores.append([hard_auc, naive_auc, hard_acc, naive_acc ])\n",
    "    \n",
    "new_df = pd.DataFrame(columns=['HardEM_auc', 'NaiveEM_auc', 'HardEM_acc', 'NaiveEM_acc'], data=scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HardEM_auc</th>\n",
       "      <th>NaiveEM_auc</th>\n",
       "      <th>HardEM_acc</th>\n",
       "      <th>NaiveEM_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.991635</td>\n",
       "      <td>0.972019</td>\n",
       "      <td>0.927632</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.994697</td>\n",
       "      <td>0.998348</td>\n",
       "      <td>0.967105</td>\n",
       "      <td>0.657895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.991859</td>\n",
       "      <td>0.945641</td>\n",
       "      <td>0.907895</td>\n",
       "      <td>0.651316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.998512</td>\n",
       "      <td>0.981005</td>\n",
       "      <td>0.848684</td>\n",
       "      <td>0.605263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.923519</td>\n",
       "      <td>0.982051</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.480263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.659994</td>\n",
       "      <td>0.777506</td>\n",
       "      <td>0.730263</td>\n",
       "      <td>0.828947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.505040</td>\n",
       "      <td>0.481423</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.802632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.575974</td>\n",
       "      <td>0.806140</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.809211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.688743</td>\n",
       "      <td>0.928716</td>\n",
       "      <td>0.269737</td>\n",
       "      <td>0.888158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.480632</td>\n",
       "      <td>0.890788</td>\n",
       "      <td>0.835526</td>\n",
       "      <td>0.171053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    HardEM_auc  NaiveEM_auc  HardEM_acc  NaiveEM_acc\n",
       "0     0.991635     0.972019    0.927632     0.500000\n",
       "1     0.994697     0.998348    0.967105     0.657895\n",
       "2     0.991859     0.945641    0.907895     0.651316\n",
       "3     0.998512     0.981005    0.848684     0.605263\n",
       "4     0.923519     0.982051    0.828947     0.480263\n",
       "..         ...          ...         ...          ...\n",
       "95    0.659994     0.777506    0.730263     0.828947\n",
       "96    0.505040     0.481423    0.789474     0.802632\n",
       "97    0.575974     0.806140    0.315789     0.809211\n",
       "98    0.688743     0.928716    0.269737     0.888158\n",
       "99    0.480632     0.890788    0.835526     0.171053\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_df[new_df['HardEM_auc']-new_df['NaiveEM_auc']>0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_df[new_df['HardEM_acc']-new_df['NaiveEM_acc']>0].index) #How many times our accuracy was higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "how_auc = new_df[new_df['HardEM_auc']-new_df['NaiveEM_auc']>0] #How many times our AUC score was higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1151441516857973"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(how_auc['HardEM_auc']-how_auc['NaiveEM_auc']).mean() #Mean of outperformance for AUC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14526740237691008"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(how_auc['HardEM_acc']-how_auc['NaiveEM_acc']).mean() #Mean of outperformance for accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
