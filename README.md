This is an implementation of a 'Hard EM' algorithm designed from datasets coming from survival analysis. It takes into account a latent cured subpopulation, and assigns actual (hard) cure labels to censored individuals. Non-censored individuals are not cured, whereas censored individuals consist of a mix of cured and not cured individuals. This is an example of learning from positive and unlabeled data (PU learning). The algorithm is implemented using the using Sequential Least Squares Programming (SLSQP) algorithm from SciPy, and is contained in the module 'HardEM_0.py'. The input is a collection of rows containing covariates (predictors) for the censored individuals, as well as covariates for the noncensored individuals, and the output is the missing cure labels for the censored individuals. In the file 'naive.py' this output is fed into logistic regression, by selecting the option 'use_HardEM', in the 'naive_fit' function.

The file 'make_df.py' is used to generate data sets consisting of censored and noncensored individuals for which we know all of the cure labels, so that we can test our algorithm against simpler alternatives such as e.g. populating missing cure labels for censored individuals by guessing a 50% probability of being cured, etc. This is done by labeling a subset of the non-cured individuals as censored, labeling all cured individuals as censored, and then and comparing the outputs of both algorithms. When labeling non-cured individuals as censored, there are two options: (i) 'selected completely at random' (SCAR) which assigns a probability of being censored given one is not cured, independent of the individual's attributes (covariates), and (ii) violating SCAR by making the latter probability a function of the attributes. The notebook 'test_algorithm_scrap.ipynb' contains the results of the tests under SCAR, and 'testing_noscar.ipynb' contains the results of the tests under NO SCAR. In particular, our algorithm performs better using log loss, AUC score, and accuracy as metrics against the simpler alternatives in the vast majority of tests. 

Finally, the notebook 'demo_hard_em.ipynb' contains a demo showing how to use our algorithm for a well known real life melanoma dataset. It should be noted our algorithm is used to populate the missing cure labels for the censored individuals, which is then fed into classical logistic regression using Scikit-learn.

This work is the result of a collaboration with Nemanja Kosovalic and Sandip Barui from the Department of Mathematics and Statistics, at the University of South Alabama. For questions please contact Nemanja Kosovalic at n.kosovalic@gmail.com.
